{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env OPENAI_API_KEY =\n",
    "%env QDRANT_URL = \n",
    "%env QDRANT_API_KEY = \n",
    "%env LANGCHAIN_API_KEY=\n",
    "LANGCHAIN_TRACING_V2=\"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4\n",
    "import os\n",
    "from typing import Sequence\n",
    "from langchain.chains import create_retrieval_chain, create_history_aware_retriever\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.messages import AIMessage, HumanMessage, BaseMessage\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHATGPT_API_KEY = os.getenv(\"COHERE_API_KEY\")\n",
    "QDRANT_URL = os.getenv(\"QDRANT_URL\")\n",
    "QDRANT_API_KEY = os.getenv(\"QDRANT_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load, chunk and index the contents of the blog to create a retriever.\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "                \"https://pyvo.readthedocs.io/en/latest/index.html#\",\n",
    "                \"https://pyvo.readthedocs.io/en/latest/registry/index.html\",\n",
    "                \"https://pyvo.readthedocs.io/en/latest/discover/index.html\",\n",
    "                \"https://pyvo.readthedocs.io/en/latest/io/vosi.html\",\n",
    "                \"https://pyvo.readthedocs.io/en/latest/io/uws.html\",\n",
    "                \"https://pyvo.readthedocs.io/en/latest/api/pyvo.auth.AuthSession.html#pyvo.auth.AuthSession\",\n",
    "                \"https://pyvo.readthedocs.io/en/latest/api/pyvo.auth.AuthURLs.html#pyvo.auth.AuthURLs\",\n",
    "                \"https://pyvo.readthedocs.io/en/latest/samp.html\",\n",
    "                \"https://pyvo.readthedocs.io/en/latest/api/pyvo.auth.CredentialStore.html#pyvo.auth.CredentialStore\",\n",
    "                \"https://pyvo.readthedocs.io/en/latest/mivot/index.html\",\n",
    "                \"https://pyvo.readthedocs.io/en/latest/mivot/index.html\",\n",
    "                \"https://pyvo.readthedocs.io/en/latest/utils/prototypes.html\",\n",
    "                ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "\n",
    "vectorstore = QdrantVectorStore.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    "    url=QDRANT_URL,\n",
    "    prefer_grpc=True,\n",
    "    api_key=QDRANT_API_KEY,\n",
    "    collection_name=\"test_documents\",\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Incorporate the retriever into a question-answering chain.\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks related to astronomy, astrophysics and any other discipline that derives from this two. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"any questions. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise unless asked otherwise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "contextualize_q_system_prompt = (\n",
    "    \"Given a chat history and the latest user question \"\n",
    "    \"which might reference context in the chat history, \"\n",
    "    \"formulate a standalone question which can be understood \"\n",
    "    \"without the chat history. Do NOT answer the question, \"\n",
    "    \"just reformulate it if needed and otherwise return it as is.\"\n",
    ")\n",
    "\n",
    "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", contextualize_q_system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm, retriever, contextualize_q_prompt\n",
    ")\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        MessagesPlaceholder(\"chat_history\"),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    input: str\n",
    "    chat_history: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    context: str\n",
    "    answer: str\n",
    "\n",
    "\n",
    "def call_model(state: State):\n",
    "    response = rag_chain.invoke(state)\n",
    "    return {\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(state[\"input\"]),\n",
    "            AIMessage(response[\"answer\"]),\n",
    "        ],\n",
    "        \"context\": response[\"context\"],\n",
    "        \"answer\": response[\"answer\"],\n",
    "    }\n",
    "\n",
    "\n",
    "workflow = StateGraph(state_schema=State)\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n",
    "result = app.invoke(\n",
    "    {\"input\": \"What is PyVo?\"},\n",
    "    config=config,\n",
    ")\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = app.invoke(\n",
    "    {\"input\": \"What protocols does it support?\"},\n",
    "    config=config,\n",
    ")\n",
    "print(result[\"answer\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
